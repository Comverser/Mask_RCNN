{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd2XjfAfKigQ"
   },
   "source": [
    "## Mask R-CNN - Inspect Trained Model\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-12 15:59:13.992706+09:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "exp_day = str(date.today())\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "_day = str(time_record)[:10]\n",
    "_time = str(time_record.time())[:8]\n",
    "\n",
    "print(datetime.now(KST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1642064009549,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "I8EKdIcJKigT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/s/anaconda3/envs/maskrcnn/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../..\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import total_seg\n",
    "import total2_bbox\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "SEG_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_seg.h5\")  # epoch 145\n",
    "BBOX_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_bbox.h5\")  # epoch 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwhLBABXKigU"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1642064012266,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "rqCXnXXsKigV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                15\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           seg\n",
      "NUM_CLASSES                    3\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                51\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           bbox\n",
      "NUM_CLASSES                    39\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                30\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SInferenceConfig(total_seg.ParkConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "class BInferenceConfig(total2_bbox.ParkConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "seg_config = SInferenceConfig()\n",
    "seg_config.display()\n",
    "\n",
    "bbox_config = BInferenceConfig()\n",
    "bbox_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcygQBFHKigV"
   },
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1642064016129,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "D0hPsCocKigW"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1642064017737,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "wNUS9L-wKigW"
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# tet = glob.glob('/data/DatasetSeg_Final/*')\n",
    "# print(tet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtkizNphKigX"
   },
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7665,
     "status": "ok",
     "timestamp": 1642064028541,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "kAp-aD-ZKigX",
    "outputId": "0165fe9d-4623-4d41-8bac-eaa512c56c24"
   },
   "outputs": [],
   "source": [
    "bbox_data_path = 'Dataset2d'\n",
    "\n",
    "# BBOX 모델 Load Validation Dataset\n",
    "bbox_dataset = total2_bbox.ParkDataset()\n",
    "bbox_dataset.load_park(bbox_data_path, \"test\")\n",
    "bbox_dataset.prepare()\n",
    "print(\"bbox_dataset Images: {}\\nClasses: {}\".format(len(bbox_dataset.image_ids), bbox_dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset2dSeg-test/라벨링데이터\n",
      "Dataset2dSeg-test/원천데이터\n"
     ]
    }
   ],
   "source": [
    "seg_data_path = 'Dataset2dSeg'\n",
    "\n",
    "# SEG 모델 Load Validation Dataset\n",
    "seg_dataset = total_seg.ParkDataset()\n",
    "seg_dataset.load_park(seg_data_path, \"test\")\n",
    "seg_dataset.prepare()\n",
    "print(\"seg_dataset Images: {}\\nClasses: {}\".format(len(seg_dataset.image_ids), seg_dataset.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4kNkyHGKigY"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12285,
     "status": "ok",
     "timestamp": 1642064047946,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "amAZenabKigY",
    "outputId": "9c52d4ff-782f-4fc6-f789-90437cb4e0bb"
   },
   "outputs": [],
   "source": [
    "seg_model = modellib.MaskRCNN(mode=\"inference\", model_dir=SEG_MODEL_PATH, config=seg_config)\n",
    "bbox_model = modellib.MaskRCNN(mode=\"inference\", model_dir=BBOX_MODEL_PATH, config=bbox_config)\n",
    "\n",
    "print(\"Loading seg_weights \", SEG_MODEL_PATH)\n",
    "seg_model.load_weights(SEG_MODEL_PATH, by_name=True)\n",
    "\n",
    "print(\"Loading bbox_weights \", BBOX_MODEL_PATH)\n",
    "bbox_model.load_weights(BBOX_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_class_names = [\"BG\", \"Parking Space\", \"Driveable Space\"]\n",
    "\n",
    "bbox_class_names = [\"BG\", \"Car\", \"Van\", \"Other Vehicle\", \"Motorbike\", \"Bicycle\", \"Electric Scooter\", \"Adult\", \"Child\", \"Stroller\", \"Shopping Cart\", \"Gate Arm\", \n",
    "               \"Parking Block\", \"Speed Bump\", \"Traffic Pole\", \"Traffic Cone\", \"Traffic Drum\", \"Traffic Barricade\", \"Cylindrical Bollard\", \"U-shaped Bollard\", \n",
    "               \"Other Road Barriers\", \"No Parking Stand\", \"Adjustable Parking Pole\", \"Waste Tire\", \"Planter Barrier\", \"Water Container\", \"Movable Obstacle\", \n",
    "               \"Barrier Gate\", \"Electric Car Charger\", \"Parking Meter\", \"Parking Sign\", \"Traffic Light\", \"Pedestrian Light\", \"Street Sign\", \"Disabled Parking Space\", \n",
    "               \"Pregnant Parking Space\", \"Electric Car Parking Space\", \"Two-wheeled Vehicle Parking Space\", \"Other Parking Space\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGAayAI-KigY"
   },
   "source": [
    "## Run Detection(SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8923,
     "status": "ok",
     "timestamp": 1642064060398,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "wfNcyAHLKigY",
    "outputId": "8fcf4f2b-3647-41a8-ad5a-c12df84ba7ff"
   },
   "outputs": [],
   "source": [
    "# SEG 모델\n",
    "import random\n",
    "import visualize\n",
    "image_id = random.choice(seg_dataset.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(seg_dataset, seg_config, image_id, use_mini_mask=False)\n",
    "info = seg_dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       seg_dataset.image_reference(image_id)))\n",
    "\n",
    "results = seg_model.detect([image], verbose=1)\n",
    "\n",
    "# 결과 보기\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances_seg(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            seg_class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rKOnJyiKigZ"
   },
   "source": [
    "### Precision-Recall(SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_compute_matches_seg(gt_boxes, gt_class_ids, gt_masks,\n",
    "                    pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "                    iou_threshold=0.5, score_threshold=0.0):\n",
    "    \"\"\"Finds matches between prediction and ground truth instances.\n",
    "\n",
    "    Returns:\n",
    "        gt_match: 1-D array. For each GT box it has the index of the matched\n",
    "                  predicted box.\n",
    "        pred_match: 1-D array. For each predicted box, it has the index of\n",
    "                    the matched ground truth box.\n",
    "        overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "    \"\"\"\n",
    "    # Trim zero padding\n",
    "    # TODO: cleaner to do zero unpadding upstream\n",
    "    gt_boxes = utils.trim_zeros(gt_boxes)\n",
    "    gt_masks = gt_masks[..., :gt_boxes.shape[0]]\n",
    "    pred_boxes = utils.trim_zeros(pred_boxes)\n",
    "    pred_scores = pred_scores[:pred_boxes.shape[0]]\n",
    "    # Sort predictions by score from high to low\n",
    "    indices = np.argsort(pred_scores)[::-1]\n",
    "    pred_boxes = pred_boxes[indices]\n",
    "    pred_class_ids = pred_class_ids[indices]\n",
    "    pred_scores = pred_scores[indices]\n",
    "    pred_masks = pred_masks[..., indices]\n",
    "\n",
    "    # Compute IoU overlaps [pred_masks, gt_masks]\n",
    "    overlaps = utils.compute_overlaps_masks(pred_masks,gt_masks)\n",
    "\n",
    "    # Loop through predictions and find matching ground truth boxes\n",
    "    match_count = 0\n",
    "    pred_match = -1 * np.ones([pred_boxes.shape[0]])\n",
    "    gt_match = -1 * np.ones([gt_boxes.shape[0]])\n",
    "\n",
    "    # print(\"(compute_matches) overlaps : \",overlaps)\n",
    "\n",
    "    # print(\"(compute_matches) pred_class_ids : \",pred_class_ids)\n",
    "    # print(\"(compute_matches) gt_class_ids : \",gt_class_ids)\n",
    "\n",
    "    comp = []\n",
    "\n",
    "    for i in range(len(pred_boxes)):\n",
    "        # Find best matching ground truth box\n",
    "        # 1. Sort matches by score\n",
    "        sorted_ixs = np.argsort(overlaps[i])[::-1]\n",
    "        # print(\"(compute_matches) sorted_ixs : \",sorted_ixs)\n",
    "        # 2. Remove low scores\n",
    "        low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\n",
    "        if low_score_idx.size > 0:\n",
    "            sorted_ixs = sorted_ixs[:low_score_idx[0]]\n",
    "        # 3. Find the match\n",
    "        for j in sorted_ixs:\n",
    "            # If ground truth box is already matched, go to next one\n",
    "            if gt_match[j] > -1:\n",
    "                continue\n",
    "            # If we reach IoU smaller than the threshold, end the loop\n",
    "            iou = overlaps[i, j]\n",
    "            # print('(compute_matches) **gt_class_ids1 : ',gt_class_ids[j])\n",
    "            # print('(compute_matches) **pred_class_ids1 : ',pred_class_ids[i])\n",
    "            # print('(compute_matches) **pred_scores : ',pred_scores[i])\n",
    "            # print('(compute_matches) **iou : ',iou)\n",
    "\n",
    "            if iou < iou_threshold:\n",
    "                break\n",
    "\n",
    "            # print('(compute_matches) **gt_class_ids2 : ',gt_class_ids[j])\n",
    "            # print('(compute_matches) **pred_class_ids2 : ',pred_class_ids[i])\n",
    "            # print('(compute_matches) **iou : ',iou)\n",
    "\n",
    "            comp.append([gt_class_ids[j],pred_class_ids[i],iou,pred_scores[i]])\n",
    "            \n",
    "            # Do we have a match?\n",
    "            if pred_class_ids[i] == gt_class_ids[j]:\n",
    "                match_count += 1\n",
    "                gt_match[j] = i\n",
    "                pred_match[i] = j\n",
    "                break\n",
    "    # print('(compute_matches) gt_match2',gt_match)\n",
    "    # print('(compute_matches) pred_match2',pred_match)\n",
    "\n",
    "    for i,gt_m in enumerate(gt_match) :\n",
    "        if gt_m == -1 :\n",
    "            # print('(compute_matches) **gt_class_ids2 : ',gt_class_ids[i])\n",
    "            comp.append([gt_class_ids[i]])\n",
    "\n",
    "\n",
    "    return gt_match, pred_match, overlaps,comp\n",
    "\n",
    "\n",
    "def d_compute_ap_seg(gt_boxes, gt_class_ids, gt_masks,\n",
    "               pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "               iou_threshold=0.5):\n",
    "    \"\"\"Compute Average Precision at a set IoU threshold (default 0.5).\n",
    "\n",
    "    Returns:\n",
    "    mAP: Mean Average Precision\n",
    "    precisions: List of precisions at different class score thresholds.\n",
    "    recalls: List of recall values at different class score thresholds.\n",
    "    overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "    \"\"\"\n",
    "    # Get matches and overlaps\n",
    "    gt_match, pred_match, overlaps,comp = d_compute_matches_seg(\n",
    "        gt_boxes, gt_class_ids, gt_masks,\n",
    "        pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "        iou_threshold)\n",
    "\n",
    "    # Compute precision and recall at each prediction box step\n",
    "    precisions = np.cumsum(pred_match > -1) / (np.arange(len(pred_match)) + 1)\n",
    "    recalls = np.cumsum(pred_match > -1).astype(np.float32) / len(gt_match)\n",
    "\n",
    "    # Pad with start and end values to simplify the math\n",
    "    precisions = np.concatenate([[0], precisions, [0]])\n",
    "    recalls = np.concatenate([[0], recalls, [1]])\n",
    "\n",
    "    # Ensure precision values decrease but don't increase. This way, the\n",
    "    # precision value at each recall threshold is the maximum it can be\n",
    "    # for all following recall thresholds, as specified by the VOC paper.\n",
    "    for i in range(len(precisions) - 2, -1, -1):\n",
    "        precisions[i] = np.maximum(precisions[i], precisions[i + 1])\n",
    "\n",
    "    # Compute mean AP over recall range\n",
    "    indices = np.where(recalls[:-1] != recalls[1:])[0] + 1\n",
    "    mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                 precisions[indices])\n",
    "\n",
    "    return mAP, precisions, recalls, overlaps,comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1637746270240,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "RwwBDoAoKigZ",
    "outputId": "54ba9bd0-1ee8-4bf7-fb09-a194c74c3557"
   },
   "outputs": [],
   "source": [
    "AP, precisions, recalls, overlaps,comp = d_compute_ap_seg(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "visualize.plot_precision_recall(AP, precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "executionInfo": {
     "elapsed": 1641,
     "status": "ok",
     "timestamp": 1637746325460,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "S1XY_y9xKigZ",
    "outputId": "5e893072-e4bc-4018-e3d5-bd9b1b380f1d"
   },
   "outputs": [],
   "source": [
    "# Grid of ground truth objects and their predictions\n",
    "visualize.plot_overlaps(gt_class_id, r['class_ids'], r['scores'],\n",
    "                        overlaps, seg_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vxD-IV9KigZ"
   },
   "source": [
    "## Run Detection(BBOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1637747706989,
     "user": {
      "displayName": "GNICT GNICT",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18438577818320315838"
     },
     "user_tz": -540
    },
    "id": "pnS1eUNdKigZ",
    "outputId": "50d5fc33-4a3e-4997-ed1d-bff5d2de471b"
   },
   "outputs": [],
   "source": [
    "# BBOX 모델\n",
    "import random\n",
    "image_id = random.choice(bbox_dataset.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(bbox_dataset, bbox_config, image_id, use_mini_mask=False)\n",
    "info = bbox_dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       bbox_dataset.image_reference(image_id)))\n",
    "# Run object detection\n",
    "results = bbox_model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            bbox_class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall(BBOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_compute_matches(gt_boxes, gt_class_ids, gt_masks,\n",
    "                    pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "                    iou_threshold=0.1, score_threshold=0.0):\n",
    "    \"\"\"Finds matches between prediction and ground truth instances.\n",
    "\n",
    "    Returns:\n",
    "        gt_match: 1-D array. For each GT box it has the index of the matched\n",
    "                  predicted box.\n",
    "        pred_match: 1-D array. For each predicted box, it has the index of\n",
    "                    the matched ground truth box.\n",
    "        overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "    \"\"\"\n",
    "    # Trim zero padding\n",
    "    # TODO: cleaner to do zero unpadding upstream\n",
    "    gt_boxes = utils.trim_zeros(gt_boxes)\n",
    "    gt_masks = gt_masks[..., :gt_boxes.shape[0]]\n",
    "    pred_boxes = utils.trim_zeros(pred_boxes)\n",
    "    pred_scores = pred_scores[:pred_boxes.shape[0]]\n",
    "    # Sort predictions by score from high to low\n",
    "    indices = np.argsort(pred_scores)[::-1]\n",
    "    pred_boxes = pred_boxes[indices]\n",
    "    pred_class_ids = pred_class_ids[indices]\n",
    "    pred_scores = pred_scores[indices]\n",
    "    pred_masks = pred_masks[..., indices]\n",
    "\n",
    "    # Compute IoU overlaps [pred_masks, gt_masks]\n",
    "    overlaps = utils.compute_overlaps(pred_boxes,gt_boxes)\n",
    "\n",
    "    # Loop through predictions and find matching ground truth boxes\n",
    "    match_count = 0\n",
    "    pred_match = -1 * np.ones([pred_boxes.shape[0]])\n",
    "    gt_match = -1 * np.ones([gt_boxes.shape[0]])\n",
    "\n",
    "    comp = []\n",
    "\n",
    "    for i in range(len(pred_boxes)):\n",
    "        # Find best matching ground truth box\n",
    "        # 1. Sort matches by score\n",
    "        sorted_ixs = np.argsort(overlaps[i])[::-1]\n",
    "        # print(\"(compute_matches) sorted_ixs : \",sorted_ixs)\n",
    "        # 2. Remove low scores\n",
    "        low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\n",
    "        if low_score_idx.size > 0:\n",
    "            sorted_ixs = sorted_ixs[:low_score_idx[0]]\n",
    "        # 3. Find the match\n",
    "        for j in sorted_ixs:\n",
    "            # If ground truth box is already matched, go to next one\n",
    "            if gt_match[j] > -1:\n",
    "                continue\n",
    "            iou = overlaps[i, j]\n",
    "\n",
    "            if iou < iou_threshold:\n",
    "                break\n",
    "\n",
    "            comp.append([gt_class_ids[j],pred_class_ids[i],iou,pred_scores[i]])\n",
    "            \n",
    "            # Do we have a match?\n",
    "            if pred_class_ids[i] == gt_class_ids[j]:\n",
    "                match_count += 1\n",
    "                gt_match[j] = i\n",
    "                pred_match[i] = j\n",
    "                break\n",
    "    # print('(compute_matches) gt_match2',gt_match)\n",
    "    # print('(compute_matches) pred_match2',pred_match)\n",
    "\n",
    "    for i,gt_m in enumerate(gt_match) :\n",
    "        if gt_m == -1 :\n",
    "            # print('(compute_matches) **gt_class_ids2 : ',gt_class_ids[i])\n",
    "            comp.append([gt_class_ids[i]])\n",
    "\n",
    "\n",
    "    return gt_match, pred_match, overlaps,comp\n",
    "\n",
    "\n",
    "def d_compute_ap(gt_boxes, gt_class_ids, gt_masks,\n",
    "               pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "               iou_threshold=0.1):\n",
    "    \"\"\"Compute Average Precision at a set IoU threshold (default 0.5).\n",
    "\n",
    "    Returns:\n",
    "    mAP: Mean Average Precision\n",
    "    precisions: List of precisions at different class score thresholds.\n",
    "    recalls: List of recall values at different class score thresholds.\n",
    "    overlaps: [pred_boxes, gt_boxes] IoU overlaps.\n",
    "    \"\"\"\n",
    "    # Get matches and overlaps\n",
    "    gt_match, pred_match, overlaps,comp = d_compute_matches(\n",
    "        gt_boxes, gt_class_ids, gt_masks,\n",
    "        pred_boxes, pred_class_ids, pred_scores, pred_masks,\n",
    "        iou_threshold)\n",
    "\n",
    "    # Compute precision and recall at each prediction box step\n",
    "    precisions = np.cumsum(pred_match > -1) / (np.arange(len(pred_match)) + 1)\n",
    "    recalls = np.cumsum(pred_match > -1).astype(np.float32) / len(gt_match)\n",
    "\n",
    "    # Pad with start and end values to simplify the math\n",
    "    precisions = np.concatenate([[0], precisions, [0]])\n",
    "    recalls = np.concatenate([[0], recalls, [1]])\n",
    "\n",
    "    # Ensure precision values decrease but don't increase. This way, the\n",
    "    # precision value at each recall threshold is the maximum it can be\n",
    "    # for all following recall thresholds, as specified by the VOC paper.\n",
    "    for i in range(len(precisions) - 2, -1, -1):\n",
    "        precisions[i] = np.maximum(precisions[i], precisions[i + 1])\n",
    "\n",
    "    # Compute mean AP over recall range\n",
    "    indices = np.where(recalls[:-1] != recalls[1:])[0] + 1\n",
    "    mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\n",
    "                 precisions[indices])\n",
    "\n",
    "    return mAP, precisions, recalls, overlaps,comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw precision-recall curve\n",
    "\n",
    "AP, precisions, recalls, overlaps,comp = d_compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                          r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "visualize.plot_precision_recall(AP, precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of ground truth objects and their predictions\n",
    "\n",
    "visualize.plot_overlaps(gt_class_id, r['class_ids'], r['scores'],\n",
    "                        overlaps, bbox_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vezc_BfWKigf"
   },
   "source": [
    "### Compute mAP @ IoU=50 on Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict_bbox ={\n",
    "                1 : \"Car\" ,\n",
    "                2 : \"Van\" ,\n",
    "                3 : \"Other Vehicle\" , \n",
    "                4 : \"Motorbike\" ,\n",
    "                5 : \"Bicycle\",\n",
    "                6 : \"Electric Scooter\",\n",
    "                7 : \"Adult\",\n",
    "                8 : \"Child\",\n",
    "                9 : \"Stroller\",\n",
    "                10 : \"Shopping Cart\" ,\n",
    "                11 : \"Gate Arm\",\n",
    "                12 : \"Parking Block\",\n",
    "                13 : \"Speed Bump\",\n",
    "                14 : \"Traffic Pole\",\n",
    "                15 : \"Traffic Cone\",\n",
    "                16 : \"Traffic Drum\",\n",
    "                17 : \"Traffic Barricade\",\n",
    "                18 : \"Cylindrical Bollard\",\n",
    "                19 : \"U-shaped Bollard\",\n",
    "                20 : \"Other Road Barriers\",\n",
    "                21 : \"No Parking Stand\", \n",
    "                22 : \"Adjustable Parking Pole\",\n",
    "                23 : \"Waste Tire\",\n",
    "                24 : \"Planter Barrier\",\n",
    "                25 : \"Water Container\",\n",
    "                26 : \"Movable Obstacle\",\n",
    "                27 : \"Barrier Gate\",\n",
    "                28 : \"Electric Car Charger\",\n",
    "                29 : \"Parking Meter\",\n",
    "                30 : \"Parking Sign\",\n",
    "                31 : \"Traffic Light\",\n",
    "                32 : \"Pedestrian Light\",\n",
    "                33 : \"Street Sign\",\n",
    "                34 : \"Disabled Parking Space\",\n",
    "                35 : \"Pregnant Parking Space\",\n",
    "                36 : \"Electric Car Parking Space\",\n",
    "                37 : \"Two-wheeled Vehicle Parking Space\",\n",
    "                38 : \"Other Parking Space\" ,\n",
    "                }\n",
    "name_dict_seg ={\n",
    "                1 : \"Parking Space\",\n",
    "                2 : \"Driveable Space\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEG모델\n",
    "import csv\n",
    "\n",
    "image_ids = seg_dataset.image_ids\n",
    "APs = []\n",
    "\n",
    "with open('listiou_seg.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(seg_dataset, seg_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        molded_images = np.expand_dims(modellib.mold_image(image, seg_config), 0)\n",
    "        results = seg_model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        data_name = [seg_dataset.image_reference(image_id)]\n",
    "\n",
    "        AP, precisions, recalls, overlaps,comp =\\\n",
    "            d_compute_ap_seg(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        for c in comp :\n",
    "            c[0] = name_dict_seg[c[0]]\n",
    "            if len(c) >2:\n",
    "              c[1] = name_dict_seg[c[1]]\n",
    "            comp_n = data_name + c\n",
    "            writer.writerow(comp_n) \n",
    "        APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BBOX모델\n",
    "import csv\n",
    "\n",
    "image_ids = bbox_dataset.image_ids\n",
    "APs = []\n",
    "\n",
    "with open('listiou_bbox.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(bbox_dataset, bbox_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        molded_images = np.expand_dims(modellib.mold_image(image, bbox_config), 0)\n",
    "        results = bbox_model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        data_name = [bbox_dataset.image_reference(image_id)]\n",
    "\n",
    "        AP, precisions, recalls, overlaps,comp =\\\n",
    "            d_compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "        for c in comp :\n",
    "            c[0] = name_dict_bbox[c[0]]\n",
    "            if len(c) >2:\n",
    "              c[1] = name_dict_bbox[c[1]]\n",
    "            comp_n = data_name + c\n",
    "            writer.writerow(comp_n) \n",
    "        APs.append(AP)\n",
    "print(\"mAP @ IoU=50: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-vxD-IV9KigZ",
    "iU5sNfsAKiga",
    "KQfhvOeuKigb",
    "shd9TNMSKigc",
    "M2pxoJ6DKigc",
    "cHpIuO9_Kigd",
    "WWmnQ4BwKigd",
    "PMyQIoC-Kigd",
    "6hLQiVvAKige",
    "5WKUQVtAKige"
   ],
   "name": "total_inspect_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
